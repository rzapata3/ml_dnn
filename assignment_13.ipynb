{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "1. change the `encoding_dim` through various values (`range(2,18,2)` and store or keep track of the best loss you can get. Plot the 8 pairs of dimensions vs loss on a scatter plot\n",
    "2. using the previous assignment's model of detecting images, how does the accuracy change when you run the digit-prediction model on these 'decoded' values?\n",
    "3. apply noise to *_only_* the input of the autoencoder (not the output). demonstrate that your autoencoder can strip out noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from skimage.util import random_noise\n",
    "from keras import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather data and split into training and testing vars.\n",
    "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "\n",
    "xtrain = xtrain.astype('float32') / 255.\n",
    "xtest = xtest.astype('float32') / 255.\n",
    "xtrain = xtrain.reshape((len(xtrain), np.prod(xtrain.shape[1:])))\n",
    "xtest = xtest.reshape((len(xtest), np.prod(xtest.shape[1:])))\n",
    "xtrain.shape, xtest.shape\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Change the `encoding_dim` through various values (`range(2,18,2)` and store or keep track of the best loss you can get. Plot the 8 pairs of dimensions vs loss on a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3511 - val_loss: 0.2662\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2596 - val_loss: 0.2561\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2538 - val_loss: 0.2528\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2517 - val_loss: 0.2520\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2508 - val_loss: 0.2511\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2501 - val_loss: 0.2503\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2495 - val_loss: 0.2505\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2487 - val_loss: 0.2489\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2478 - val_loss: 0.2473\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2467 - val_loss: 0.2462\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2455 - val_loss: 0.2448\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2444 - val_loss: 0.2437\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2436 - val_loss: 0.2433\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2429 - val_loss: 0.2428\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2423 - val_loss: 0.2419\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2418 - val_loss: 0.2418\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2414 - val_loss: 0.2413\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2410 - val_loss: 0.2410\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2407 - val_loss: 0.2405\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2404 - val_loss: 0.2405\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2402 - val_loss: 0.2412\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2399 - val_loss: 0.2397\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2397 - val_loss: 0.2398\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2394 - val_loss: 0.2394\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2393 - val_loss: 0.2391\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2390 - val_loss: 0.2386\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2388 - val_loss: 0.2384\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2386 - val_loss: 0.2379\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2384 - val_loss: 0.2384\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2381 - val_loss: 0.2382\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2379 - val_loss: 0.2377\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2377 - val_loss: 0.2376\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2375 - val_loss: 0.2371\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2373 - val_loss: 0.2370\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2370 - val_loss: 0.2365\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2369 - val_loss: 0.2363\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2367 - val_loss: 0.2372\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2365 - val_loss: 0.2358\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2364 - val_loss: 0.2356\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2362 - val_loss: 0.2355\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2361 - val_loss: 0.2355\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2360 - val_loss: 0.2353\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2358 - val_loss: 0.2352\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2357 - val_loss: 0.2351\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2356 - val_loss: 0.2349\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2355 - val_loss: 0.2348\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2353 - val_loss: 0.2349\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2352 - val_loss: 0.2345\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2351 - val_loss: 0.2346\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2349 - val_loss: 0.2345\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2347 - val_loss: 0.2338\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2343 - val_loss: 0.2329\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2303 - val_loss: 0.2259\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2254 - val_loss: 0.2229\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2231 - val_loss: 0.2212\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2215 - val_loss: 0.2200\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2204 - val_loss: 0.2186\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2193 - val_loss: 0.2183\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2183 - val_loss: 0.2167\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2171 - val_loss: 0.2159\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2159 - val_loss: 0.2148\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2147 - val_loss: 0.2136\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2136 - val_loss: 0.2126\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2126 - val_loss: 0.2120\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2118 - val_loss: 0.2113\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2110 - val_loss: 0.2104\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2101 - val_loss: 0.2101\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2094 - val_loss: 0.2090\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2086 - val_loss: 0.2086\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2079 - val_loss: 0.2076\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2072 - val_loss: 0.2073\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2065 - val_loss: 0.2065\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2058 - val_loss: 0.2063\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2052 - val_loss: 0.2054\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2046 - val_loss: 0.2050\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2041 - val_loss: 0.2045\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2035 - val_loss: 0.2041\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2031 - val_loss: 0.2032\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2025 - val_loss: 0.2033\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.2021 - val_loss: 0.2027\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2016 - val_loss: 0.2029\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2013 - val_loss: 0.2019\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2008 - val_loss: 0.2013\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2005 - val_loss: 0.2006\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2001 - val_loss: 0.2008\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1997 - val_loss: 0.2006\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1993 - val_loss: 0.1999\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1990 - val_loss: 0.1995\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1987 - val_loss: 0.1991\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1983 - val_loss: 0.1992\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1981 - val_loss: 0.1988\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1977 - val_loss: 0.1983\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1974 - val_loss: 0.1978\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1971 - val_loss: 0.1977\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1968 - val_loss: 0.1978\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1966 - val_loss: 0.1972\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1963 - val_loss: 0.1985\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1960 - val_loss: 0.1973\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1958 - val_loss: 0.1970\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1955 - val_loss: 0.1967\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3556 - val_loss: 0.2634\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2578 - val_loss: 0.2529\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2433 - val_loss: 0.2341\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2297 - val_loss: 0.2265\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2248 - val_loss: 0.2229\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2203 - val_loss: 0.2165\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2122 - val_loss: 0.2085\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2054 - val_loss: 0.2039\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2008 - val_loss: 0.1984\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1965 - val_loss: 0.1949\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1929 - val_loss: 0.1911\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1900 - val_loss: 0.1887\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1876 - val_loss: 0.1865\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1855 - val_loss: 0.1843\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1838 - val_loss: 0.1830\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1823 - val_loss: 0.1819\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1810 - val_loss: 0.1805\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1798 - val_loss: 0.1795\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1785 - val_loss: 0.1783\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1776 - val_loss: 0.1771\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1766 - val_loss: 0.1755\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1757 - val_loss: 0.1753\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1750 - val_loss: 0.1745\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1742 - val_loss: 0.1745\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1735 - val_loss: 0.1730\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1729 - val_loss: 0.1737\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1723 - val_loss: 0.1723\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1717 - val_loss: 0.1719\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1712 - val_loss: 0.1705\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1706 - val_loss: 0.1703\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1699 - val_loss: 0.1696\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1696 - val_loss: 0.1709\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1690 - val_loss: 0.1684\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1685 - val_loss: 0.1691\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1681 - val_loss: 0.1690\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1677 - val_loss: 0.1685\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1673 - val_loss: 0.1674\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1668 - val_loss: 0.1669\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1664 - val_loss: 0.1671\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1661 - val_loss: 0.1657\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1657 - val_loss: 0.1660\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1653 - val_loss: 0.1691\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1650 - val_loss: 0.1657\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1646 - val_loss: 0.1640\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1642 - val_loss: 0.1643\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1639 - val_loss: 0.1646\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1637 - val_loss: 0.1639\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1633 - val_loss: 0.1636\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1630 - val_loss: 0.1653\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1628 - val_loss: 0.1628\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1624 - val_loss: 0.1627\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1621 - val_loss: 0.1642\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1620 - val_loss: 0.1617\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1617 - val_loss: 0.1621\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1614 - val_loss: 0.1610\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1611 - val_loss: 0.1614\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1608 - val_loss: 0.1608\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1606 - val_loss: 0.1606\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1604 - val_loss: 0.1613\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1600 - val_loss: 0.1614\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1599 - val_loss: 0.1599\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1597 - val_loss: 0.1601\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1594 - val_loss: 0.1586\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1593 - val_loss: 0.1596\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1590 - val_loss: 0.1591\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1588 - val_loss: 0.1597\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1586 - val_loss: 0.1583\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1584 - val_loss: 0.1589\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1582 - val_loss: 0.1583\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1580 - val_loss: 0.1579\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1578 - val_loss: 0.1598\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1576 - val_loss: 0.1582\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1574 - val_loss: 0.1581\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1573 - val_loss: 0.1581\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1571 - val_loss: 0.1573\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1568 - val_loss: 0.1569\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1568 - val_loss: 0.1569\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1566 - val_loss: 0.1574\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1563 - val_loss: 0.1574\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1562 - val_loss: 0.1570\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1559 - val_loss: 0.1573\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1559 - val_loss: 0.1559\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1558 - val_loss: 0.1562\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1555 - val_loss: 0.1555\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1555 - val_loss: 0.1563\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1553 - val_loss: 0.1562\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1550 - val_loss: 0.1551\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1548 - val_loss: 0.1569\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1547 - val_loss: 0.1552\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1546 - val_loss: 0.1554\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1545 - val_loss: 0.1546\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1544 - val_loss: 0.1563\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1542 - val_loss: 0.1547\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1541 - val_loss: 0.1552\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1540 - val_loss: 0.1556\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1539 - val_loss: 0.1554\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1537 - val_loss: 0.1548\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1535 - val_loss: 0.1547\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1535 - val_loss: 0.1542\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1533 - val_loss: 0.1539\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3425 - val_loss: 0.2630\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2575 - val_loss: 0.2520\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2445 - val_loss: 0.2380\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2326 - val_loss: 0.2263\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2237 - val_loss: 0.2180\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2138 - val_loss: 0.2075\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2040 - val_loss: 0.1999\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1957 - val_loss: 0.1924\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1904 - val_loss: 0.1872\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1866 - val_loss: 0.1834\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1833 - val_loss: 0.1814\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1805 - val_loss: 0.1783\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1780 - val_loss: 0.1762\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1761 - val_loss: 0.1739\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1743 - val_loss: 0.1738\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1726 - val_loss: 0.1726\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1712 - val_loss: 0.1714\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1697 - val_loss: 0.1688\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1685 - val_loss: 0.1679\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1674 - val_loss: 0.1690\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1663 - val_loss: 0.1649\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1653 - val_loss: 0.1645\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1644 - val_loss: 0.1647\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1635 - val_loss: 0.1634\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1628 - val_loss: 0.1635\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1621 - val_loss: 0.1613\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1612 - val_loss: 0.1608\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1606 - val_loss: 0.1602\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1600 - val_loss: 0.1596\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1594 - val_loss: 0.1600\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1589 - val_loss: 0.1589\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1583 - val_loss: 0.1604\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1579 - val_loss: 0.1595\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1573 - val_loss: 0.1575\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1568 - val_loss: 0.1574\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1563 - val_loss: 0.1562\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1558 - val_loss: 0.1555\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1554 - val_loss: 0.1547\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1549 - val_loss: 0.1550\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1546 - val_loss: 0.1543\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1543 - val_loss: 0.1543\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1539 - val_loss: 0.1537\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1535 - val_loss: 0.1561\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1532 - val_loss: 0.1552\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1529 - val_loss: 0.1540\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1527 - val_loss: 0.1546\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1524 - val_loss: 0.1550\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1519 - val_loss: 0.1522\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1518 - val_loss: 0.1521\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1514 - val_loss: 0.1511\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1512 - val_loss: 0.1518\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1509 - val_loss: 0.1505\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1505 - val_loss: 0.1506\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1504 - val_loss: 0.1503\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1501 - val_loss: 0.1498\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1498 - val_loss: 0.1511\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1497 - val_loss: 0.1498\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1495 - val_loss: 0.1504\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1492 - val_loss: 0.1490\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1490 - val_loss: 0.1500\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1489 - val_loss: 0.1490\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1487 - val_loss: 0.1488\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1484 - val_loss: 0.1500\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1483 - val_loss: 0.1489\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1481 - val_loss: 0.1476\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1478 - val_loss: 0.1492\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1477 - val_loss: 0.1473\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1476 - val_loss: 0.1497\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1473 - val_loss: 0.1471\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1471 - val_loss: 0.1479\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1471 - val_loss: 0.1476\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1470 - val_loss: 0.1471\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1468 - val_loss: 0.1464\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1465 - val_loss: 0.1476\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1465 - val_loss: 0.1464\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1462 - val_loss: 0.1491\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1461 - val_loss: 0.1473\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1460 - val_loss: 0.1472\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1458 - val_loss: 0.1465\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1457 - val_loss: 0.1454\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1455 - val_loss: 0.1462\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1454 - val_loss: 0.1456\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1453 - val_loss: 0.1476\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1452 - val_loss: 0.1459\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1450 - val_loss: 0.1456\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1448 - val_loss: 0.1459\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1447 - val_loss: 0.1453\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1446 - val_loss: 0.1457\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1444 - val_loss: 0.1453\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1444 - val_loss: 0.1450\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1444 - val_loss: 0.1449\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1442 - val_loss: 0.1447\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1440 - val_loss: 0.1454\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1440 - val_loss: 0.1448\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1438 - val_loss: 0.1452\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1438 - val_loss: 0.1445\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1435 - val_loss: 0.1438\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1436 - val_loss: 0.1437\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1434 - val_loss: 0.1436\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1434 - val_loss: 0.1439\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3383 - val_loss: 0.2621\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2574 - val_loss: 0.2534\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2453 - val_loss: 0.2321\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2224 - val_loss: 0.2152\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2106 - val_loss: 0.2034\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1985 - val_loss: 0.1919\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1885 - val_loss: 0.1890\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1822 - val_loss: 0.1788\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1772 - val_loss: 0.1742\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1726 - val_loss: 0.1690\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1686 - val_loss: 0.1667\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1654 - val_loss: 0.1624\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1627 - val_loss: 0.1595\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1605 - val_loss: 0.1590\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1584 - val_loss: 0.1569\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1566 - val_loss: 0.1556\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1551 - val_loss: 0.1528\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1535 - val_loss: 0.1518\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1521 - val_loss: 0.1498\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1510 - val_loss: 0.1492\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1498 - val_loss: 0.1486\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1489 - val_loss: 0.1479\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1478 - val_loss: 0.1457\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1471 - val_loss: 0.1455\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1463 - val_loss: 0.1453\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1454 - val_loss: 0.1448\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1449 - val_loss: 0.1440\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1442 - val_loss: 0.1434\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1437 - val_loss: 0.1432\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1429 - val_loss: 0.1420\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1424 - val_loss: 0.1416\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1419 - val_loss: 0.1415\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1414 - val_loss: 0.1404\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1409 - val_loss: 0.1408\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1405 - val_loss: 0.1394\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1401 - val_loss: 0.1392\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1396 - val_loss: 0.1391\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1392 - val_loss: 0.1393\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1389 - val_loss: 0.1378\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1385 - val_loss: 0.1374\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1381 - val_loss: 0.1376\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1377 - val_loss: 0.1365\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1374 - val_loss: 0.1365\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1371 - val_loss: 0.1365\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1367 - val_loss: 0.1355\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1363 - val_loss: 0.1353\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1361 - val_loss: 0.1349\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1357 - val_loss: 0.1359\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1354 - val_loss: 0.1349\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1352 - val_loss: 0.1349\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1349 - val_loss: 0.1341\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1344 - val_loss: 0.1347\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1341 - val_loss: 0.1336\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1335 - val_loss: 0.1331\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1329 - val_loss: 0.1322\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1324 - val_loss: 0.1315\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1318 - val_loss: 0.1316\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1312 - val_loss: 0.1299\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1308 - val_loss: 0.1308\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1304 - val_loss: 0.1306\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1300 - val_loss: 0.1290\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1298 - val_loss: 0.1285\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1293 - val_loss: 0.1285\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1291 - val_loss: 0.1296\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1287 - val_loss: 0.1277\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1284 - val_loss: 0.1287\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1282 - val_loss: 0.1270\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1279 - val_loss: 0.1274\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1277 - val_loss: 0.1269\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1273 - val_loss: 0.1274\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1272 - val_loss: 0.1265\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1269 - val_loss: 0.1260\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1266 - val_loss: 0.1256\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1264 - val_loss: 0.1267\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1262 - val_loss: 0.1255\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1260 - val_loss: 0.1272\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1259 - val_loss: 0.1253\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1256 - val_loss: 0.1251\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1253 - val_loss: 0.1249\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1254 - val_loss: 0.1258\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1251 - val_loss: 0.1246\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1248 - val_loss: 0.1249\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1247 - val_loss: 0.1242\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1245 - val_loss: 0.1240\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1244 - val_loss: 0.1242\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1242 - val_loss: 0.1240\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1241 - val_loss: 0.1242\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1239 - val_loss: 0.1228\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1236 - val_loss: 0.1235\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1236 - val_loss: 0.1250\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1234 - val_loss: 0.1230\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1232 - val_loss: 0.1234\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1231 - val_loss: 0.1230\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1230 - val_loss: 0.1231\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1228 - val_loss: 0.1223\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1228 - val_loss: 0.1228\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1226 - val_loss: 0.1240\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1225 - val_loss: 0.1222\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1223 - val_loss: 0.1221\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1221 - val_loss: 0.1221\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.3356 - val_loss: 0.2628\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2572 - val_loss: 0.2516\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2444 - val_loss: 0.2381\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2323 - val_loss: 0.2211\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2114 - val_loss: 0.2018\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1990 - val_loss: 0.1953\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1914 - val_loss: 0.1849\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1821 - val_loss: 0.1766\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1746 - val_loss: 0.1711\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1697 - val_loss: 0.1673\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1655 - val_loss: 0.1617\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1616 - val_loss: 0.1596\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1575 - val_loss: 0.1530\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1546 - val_loss: 0.1511\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1520 - val_loss: 0.1505\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1500 - val_loss: 0.1480\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1484 - val_loss: 0.1449\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1466 - val_loss: 0.1476\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1453 - val_loss: 0.1431\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1441 - val_loss: 0.1426\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1428 - val_loss: 0.1410\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1418 - val_loss: 0.1410\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1407 - val_loss: 0.1396\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1397 - val_loss: 0.1389\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1388 - val_loss: 0.1372\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1382 - val_loss: 0.1363\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1372 - val_loss: 0.1352\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1366 - val_loss: 0.1346\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1359 - val_loss: 0.1332\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1351 - val_loss: 0.1332\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1346 - val_loss: 0.1333\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1339 - val_loss: 0.1321\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1333 - val_loss: 0.1324\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1327 - val_loss: 0.1309\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1320 - val_loss: 0.1315\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1314 - val_loss: 0.1308\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1307 - val_loss: 0.1290\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1299 - val_loss: 0.1291\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1293 - val_loss: 0.1281\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1286 - val_loss: 0.1269\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1280 - val_loss: 0.1267\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1273 - val_loss: 0.1263\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1270 - val_loss: 0.1260\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1265 - val_loss: 0.1255\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1260 - val_loss: 0.1251\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1256 - val_loss: 0.1258\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1253 - val_loss: 0.1245\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1249 - val_loss: 0.1237\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1245 - val_loss: 0.1245\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1241 - val_loss: 0.1239\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1237 - val_loss: 0.1219\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1234 - val_loss: 0.1233\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1231 - val_loss: 0.1223\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1227 - val_loss: 0.1218\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1224 - val_loss: 0.1219\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1222 - val_loss: 0.1217\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1218 - val_loss: 0.1208\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1216 - val_loss: 0.1206\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1213 - val_loss: 0.1207\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1212 - val_loss: 0.1199\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1207 - val_loss: 0.1196\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1204 - val_loss: 0.1205\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1203 - val_loss: 0.1196\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1201 - val_loss: 0.1195\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1198 - val_loss: 0.1196\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1196 - val_loss: 0.1187\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1194 - val_loss: 0.1189\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1192 - val_loss: 0.1188\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1190 - val_loss: 0.1184\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1187 - val_loss: 0.1185\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1186 - val_loss: 0.1182\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1182 - val_loss: 0.1175\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1182 - val_loss: 0.1176\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1179 - val_loss: 0.1170\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1179 - val_loss: 0.1175\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1176 - val_loss: 0.1165\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1173 - val_loss: 0.1167\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1173 - val_loss: 0.1164\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1171 - val_loss: 0.1176\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1169 - val_loss: 0.1163\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1168 - val_loss: 0.1164\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1166 - val_loss: 0.1154\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1164 - val_loss: 0.1155\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1162 - val_loss: 0.1170\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1162 - val_loss: 0.1154\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1159 - val_loss: 0.1160\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1158 - val_loss: 0.1149\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1157 - val_loss: 0.1155\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1154 - val_loss: 0.1156\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1154 - val_loss: 0.1150\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1152 - val_loss: 0.1143\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1151 - val_loss: 0.1141\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1149 - val_loss: 0.1150\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1149 - val_loss: 0.1147\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1147 - val_loss: 0.1150\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1145 - val_loss: 0.1146\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1144 - val_loss: 0.1138\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1144 - val_loss: 0.1144\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1142 - val_loss: 0.1140\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1140 - val_loss: 0.1136\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3321 - val_loss: 0.2645\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2581 - val_loss: 0.2520\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2410 - val_loss: 0.2295\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2229 - val_loss: 0.2141\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2086 - val_loss: 0.2024\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1971 - val_loss: 0.1909\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1866 - val_loss: 0.1816\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1792 - val_loss: 0.1781\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1734 - val_loss: 0.1698\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1688 - val_loss: 0.1663\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1644 - val_loss: 0.1615\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1606 - val_loss: 0.1581\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1571 - val_loss: 0.1567\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1537 - val_loss: 0.1515\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1506 - val_loss: 0.1523\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1484 - val_loss: 0.1452\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1463 - val_loss: 0.1451\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1447 - val_loss: 0.1436\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1431 - val_loss: 0.1419\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1419 - val_loss: 0.1404\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1406 - val_loss: 0.1397\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1394 - val_loss: 0.1368\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1383 - val_loss: 0.1376\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1370 - val_loss: 0.1356\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1358 - val_loss: 0.1344\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1347 - val_loss: 0.1326\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1338 - val_loss: 0.1331\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1329 - val_loss: 0.1303\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1320 - val_loss: 0.1305\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1312 - val_loss: 0.1298\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1305 - val_loss: 0.1297\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1296 - val_loss: 0.1278\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1288 - val_loss: 0.1287\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1280 - val_loss: 0.1265\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1273 - val_loss: 0.1258\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1265 - val_loss: 0.1263\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1259 - val_loss: 0.1256\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1253 - val_loss: 0.1231\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1245 - val_loss: 0.1240\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1240 - val_loss: 0.1233\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1236 - val_loss: 0.1209\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1230 - val_loss: 0.1214\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1227 - val_loss: 0.1220\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1221 - val_loss: 0.1228\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1217 - val_loss: 0.1206\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1213 - val_loss: 0.1204\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1209 - val_loss: 0.1203\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1204 - val_loss: 0.1195\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1201 - val_loss: 0.1196\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1196 - val_loss: 0.1199\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1195 - val_loss: 0.1205\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1190 - val_loss: 0.1181\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1188 - val_loss: 0.1177\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1184 - val_loss: 0.1176\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1181 - val_loss: 0.1171\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1177 - val_loss: 0.1173\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1176 - val_loss: 0.1173\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1172 - val_loss: 0.1160\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1170 - val_loss: 0.1165\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1167 - val_loss: 0.1164\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1164 - val_loss: 0.1156\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1161 - val_loss: 0.1151\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1159 - val_loss: 0.1152\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1156 - val_loss: 0.1142\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1153 - val_loss: 0.1161\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1151 - val_loss: 0.1141\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1147 - val_loss: 0.1154\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1145 - val_loss: 0.1137\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1141 - val_loss: 0.1139\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1138 - val_loss: 0.1131\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1134 - val_loss: 0.1129\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1133 - val_loss: 0.1136\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1130 - val_loss: 0.1126\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1127 - val_loss: 0.1111\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1123 - val_loss: 0.1110\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1121 - val_loss: 0.1110\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1119 - val_loss: 0.1131\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1116 - val_loss: 0.1109\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1114 - val_loss: 0.1108\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1112 - val_loss: 0.1104\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1110 - val_loss: 0.1110\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1108 - val_loss: 0.1106\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1105 - val_loss: 0.1116\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1103 - val_loss: 0.1097\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1102 - val_loss: 0.1088\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1100 - val_loss: 0.1102\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1097 - val_loss: 0.1091\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1097 - val_loss: 0.1102\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1093 - val_loss: 0.1092\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1094 - val_loss: 0.1087\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1091 - val_loss: 0.1083\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1089 - val_loss: 0.1079\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1088 - val_loss: 0.1084\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1087 - val_loss: 0.1078\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1085 - val_loss: 0.1083\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1084 - val_loss: 0.1074\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1082 - val_loss: 0.1073\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1080 - val_loss: 0.1078\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1079 - val_loss: 0.1072\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1078 - val_loss: 0.1075\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3232 - val_loss: 0.2620\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2541 - val_loss: 0.2444\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2338 - val_loss: 0.2235\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2135 - val_loss: 0.2025\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1959 - val_loss: 0.1888\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1854 - val_loss: 0.1790\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1776 - val_loss: 0.1720\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1711 - val_loss: 0.1668\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1651 - val_loss: 0.1609\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1597 - val_loss: 0.1578\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1555 - val_loss: 0.1523\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1524 - val_loss: 0.1494\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1497 - val_loss: 0.1455\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1475 - val_loss: 0.1455\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1455 - val_loss: 0.1442\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1437 - val_loss: 0.1414\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1420 - val_loss: 0.1397\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1404 - val_loss: 0.1368\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1387 - val_loss: 0.1366\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1373 - val_loss: 0.1357\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1358 - val_loss: 0.1321\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1345 - val_loss: 0.1336\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1335 - val_loss: 0.1313\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1325 - val_loss: 0.1298\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1315 - val_loss: 0.1295\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1305 - val_loss: 0.1285\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1298 - val_loss: 0.1291\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1289 - val_loss: 0.1288\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1283 - val_loss: 0.1257\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1275 - val_loss: 0.1258\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1267 - val_loss: 0.1253\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1258 - val_loss: 0.1234\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1250 - val_loss: 0.1236\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1242 - val_loss: 0.1236\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1234 - val_loss: 0.1211\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1227 - val_loss: 0.1214\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1222 - val_loss: 0.1205\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1217 - val_loss: 0.1205\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1210 - val_loss: 0.1196\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1205 - val_loss: 0.1204\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1201 - val_loss: 0.1201\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1196 - val_loss: 0.1188\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1192 - val_loss: 0.1171\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1188 - val_loss: 0.1182\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1184 - val_loss: 0.1172\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1183 - val_loss: 0.1180\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1177 - val_loss: 0.1160\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1173 - val_loss: 0.1170\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1171 - val_loss: 0.1164\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1166 - val_loss: 0.1155\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1164 - val_loss: 0.1147\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1159 - val_loss: 0.1155\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1156 - val_loss: 0.1147\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1153 - val_loss: 0.1150\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1151 - val_loss: 0.1141\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1149 - val_loss: 0.1141\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1145 - val_loss: 0.1130\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1143 - val_loss: 0.1134\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1139 - val_loss: 0.1134\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1138 - val_loss: 0.1135\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1135 - val_loss: 0.1129\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1132 - val_loss: 0.1134\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1131 - val_loss: 0.1120\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1127 - val_loss: 0.1120\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1126 - val_loss: 0.1125\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1123 - val_loss: 0.1115\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1120 - val_loss: 0.1120\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1120 - val_loss: 0.1115\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1116 - val_loss: 0.1119\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1115 - val_loss: 0.1115\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1114 - val_loss: 0.1104\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1111 - val_loss: 0.1110\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1109 - val_loss: 0.1104\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1107 - val_loss: 0.1102\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1105 - val_loss: 0.1108\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1103 - val_loss: 0.1089\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1101 - val_loss: 0.1097\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1100 - val_loss: 0.1096\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1098 - val_loss: 0.1098\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1097 - val_loss: 0.1091\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1095 - val_loss: 0.1085\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1093 - val_loss: 0.1109\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1091 - val_loss: 0.1083\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1090 - val_loss: 0.1085\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1089 - val_loss: 0.1093\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1088 - val_loss: 0.1088\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1086 - val_loss: 0.1075\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1084 - val_loss: 0.1077\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1083 - val_loss: 0.1073\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1081 - val_loss: 0.1088\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1080 - val_loss: 0.1072\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1079 - val_loss: 0.1072\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1078 - val_loss: 0.1078\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1076 - val_loss: 0.1065\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1075 - val_loss: 0.1072\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1074 - val_loss: 0.1075\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1072 - val_loss: 0.1073\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1071 - val_loss: 0.1069\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1070 - val_loss: 0.1061\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1068 - val_loss: 0.1072\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3340 - val_loss: 0.2628\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2547 - val_loss: 0.2434\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2315 - val_loss: 0.2223\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2161 - val_loss: 0.2102\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2055 - val_loss: 0.2003\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1936 - val_loss: 0.1873\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1843 - val_loss: 0.1790\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1768 - val_loss: 0.1738\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1708 - val_loss: 0.1666\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1655 - val_loss: 0.1621\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1608 - val_loss: 0.1589\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1566 - val_loss: 0.1529\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1533 - val_loss: 0.1504\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1501 - val_loss: 0.1460\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1472 - val_loss: 0.1469\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1450 - val_loss: 0.1420\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1431 - val_loss: 0.1412\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1412 - val_loss: 0.1402\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1395 - val_loss: 0.1385\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1379 - val_loss: 0.1358\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1363 - val_loss: 0.1332\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1347 - val_loss: 0.1322\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1333 - val_loss: 0.1323\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1321 - val_loss: 0.1297\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1309 - val_loss: 0.1301\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1300 - val_loss: 0.1283\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1289 - val_loss: 0.1261\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1281 - val_loss: 0.1261\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1273 - val_loss: 0.1263\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1265 - val_loss: 0.1252\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1257 - val_loss: 0.1251\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1251 - val_loss: 0.1241\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1244 - val_loss: 0.1258\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1237 - val_loss: 0.1229\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1232 - val_loss: 0.1218\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1226 - val_loss: 0.1202\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1220 - val_loss: 0.1199\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1216 - val_loss: 0.1199\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1210 - val_loss: 0.1202\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1207 - val_loss: 0.1195\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1201 - val_loss: 0.1215\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1197 - val_loss: 0.1186\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1193 - val_loss: 0.1181\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1189 - val_loss: 0.1178\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1184 - val_loss: 0.1175\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1181 - val_loss: 0.1158\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1177 - val_loss: 0.1171\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1173 - val_loss: 0.1161\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1169 - val_loss: 0.1161\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1166 - val_loss: 0.1147\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1162 - val_loss: 0.1146\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1160 - val_loss: 0.1153\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1156 - val_loss: 0.1143\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1153 - val_loss: 0.1150\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1150 - val_loss: 0.1141\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1146 - val_loss: 0.1130\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1145 - val_loss: 0.1145\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1140 - val_loss: 0.1130\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1137 - val_loss: 0.1126\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1133 - val_loss: 0.1130\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1131 - val_loss: 0.1128\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1127 - val_loss: 0.1137\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1125 - val_loss: 0.1111\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1120 - val_loss: 0.1123\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1117 - val_loss: 0.1109\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1116 - val_loss: 0.1098\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1112 - val_loss: 0.1100\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1109 - val_loss: 0.1102\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1108 - val_loss: 0.1101\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1104 - val_loss: 0.1089\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1102 - val_loss: 0.1093\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1100 - val_loss: 0.1095\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1097 - val_loss: 0.1096\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1094 - val_loss: 0.1088\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1092 - val_loss: 0.1095\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1088 - val_loss: 0.1091\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1088 - val_loss: 0.1084\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1085 - val_loss: 0.1082\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1083 - val_loss: 0.1077\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1082 - val_loss: 0.1071\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1080 - val_loss: 0.1074\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1077 - val_loss: 0.1069\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1077 - val_loss: 0.1070\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1074 - val_loss: 0.1068\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1072 - val_loss: 0.1072\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1071 - val_loss: 0.1069\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1069 - val_loss: 0.1065\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1067 - val_loss: 0.1057\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1066 - val_loss: 0.1064\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1065 - val_loss: 0.1058\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1064 - val_loss: 0.1052\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1062 - val_loss: 0.1062\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1061 - val_loss: 0.1068\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1059 - val_loss: 0.1048\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1058 - val_loss: 0.1050\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1056 - val_loss: 0.1053\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1057 - val_loss: 0.1050\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1055 - val_loss: 0.1043\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1053 - val_loss: 0.1052\n"
     ]
    }
   ],
   "source": [
    "loss_score = {}\n",
    "for iter_dim in range(2,18,2):\n",
    "    # this is the size of our encoded representations\n",
    "    encoding_dim = iter_dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "    # this is our input placeholder\n",
    "    x = input_img = Input(shape=(784,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(x)\n",
    "\n",
    "\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    x = Dense(128, activation='relu')(encoded)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    decoded = Dense(784, activation='sigmoid')(x)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "\n",
    "    encoder = Model(input_img, encoded)\n",
    "\n",
    "    # create a placeholder for an encoded (32-dimensional) input\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "    # retrieve the last layer of the autoencoder model\n",
    "    dcd1 = autoencoder.layers[-1]\n",
    "    dcd2 = autoencoder.layers[-2]\n",
    "    dcd3 = autoencoder.layers[-3]\n",
    "\n",
    "    # create the decoder model\n",
    "    decoder = Model(encoded_input, dcd1(dcd2(dcd3(encoded_input))))\n",
    "\n",
    "    # compile autoencoder \n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    \n",
    "    autoencoder.fit(xtrain, xtrain,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(xtest, xtest))\n",
    "    \n",
    "    loss_score[iter_dim] = autoencoder.evaluate(xtrain, xtrain, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0.19573124536673228,\n",
       " 4: 0.15351997696956,\n",
       " 6: 0.14371606947580973,\n",
       " 8: 0.12235987691084543,\n",
       " 10: 0.11384244225819906,\n",
       " 12: 0.10793483013709386,\n",
       " 14: 0.10745247059265772,\n",
       " 16: 0.1057592625617981}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect loss scores.\n",
    "loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss Score')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(loss_score.keys(), loss_score.values())\n",
    "plt.title(\"Dim VS Loss Analysis of Autoencoder\")\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.ylabel(\"Loss Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. using the previous assignment's model of detecting images, how does the accuracy change when you run the digit-prediction model on these 'decoded' values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784) (9000, 784)\n",
      "[[0.0000000e+00 2.0861626e-07 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.0132790e-06]\n",
      " [3.2395124e-05 4.0060282e-04 3.4272671e-06 ... 4.6432018e-05\n",
      "  5.1558018e-06 1.6570091e-05]\n",
      " [0.0000000e+00 8.3446503e-07 0.0000000e+00 ... 1.4901161e-07\n",
      "  1.1920929e-07 2.3841858e-07]\n",
      " ...\n",
      " [8.9406967e-08 0.0000000e+00 0.0000000e+00 ... 2.0861626e-06\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [2.3841858e-07 4.7683716e-07 3.8444996e-06 ... 0.0000000e+00\n",
      "  4.4703484e-07 0.0000000e+00]\n",
      " [1.7881393e-07 1.1920929e-07 1.1920929e-07 ... 0.0000000e+00\n",
      "  2.6643276e-05 1.1026859e-06]]\n"
     ]
    }
   ],
   "source": [
    "# encode and decode testing data.\n",
    "encoded_imgs = encoder.predict(xtest)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "train = np.random.shuffle(decoded_imgs)\n",
    "train,test = decoded_imgs[:1000,:],decoded_imgs[1000:,:]\n",
    "print(train.shape, test.shape)\n",
    "print(decoded_imgs)\n",
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 784), (2500, 784))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test = train_test_split(decoded_imgs)\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 784), (7500, 784))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "x_train = x_train.reshape(7500, 784)\n",
    "x_test = x_test.reshape(2500, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_test.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_249 (Dense)            (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 784)               8624      \n",
      "=================================================================\n",
      "Total params: 631,914\n",
      "Trainable params: 631,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 4s 471us/step - loss: 0.0093 - accuracy: 0.0139 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 3s 340us/step - loss: 0.0092 - accuracy: 0.0111 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 3/20\n",
      "7500/7500 [==============================] - 3s 336us/step - loss: 0.0092 - accuracy: 0.0095 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 2s 333us/step - loss: 0.0092 - accuracy: 0.0089 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 3s 335us/step - loss: 0.0092 - accuracy: 0.0079 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 3s 351us/step - loss: 0.0092 - accuracy: 0.0076 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 2s 333us/step - loss: 0.0092 - accuracy: 0.0089 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 3s 333us/step - loss: 0.0092 - accuracy: 0.0081 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 2s 332us/step - loss: 0.0092 - accuracy: 0.0073 - val_loss: 0.0092 - val_accuracy: 0.0096\n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 2s 333us/step - loss: 0.0092 - accuracy: 0.0076 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 3s 334us/step - loss: 0.0092 - accuracy: 0.0079 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 3s 338us/step - loss: 0.0092 - accuracy: 0.0072 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 3s 335us/step - loss: 0.0092 - accuracy: 0.0085 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 3s 336us/step - loss: 0.0092 - accuracy: 0.0077 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 3s 334us/step - loss: 0.0092 - accuracy: 0.0085 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 3s 335us/step - loss: 0.0092 - accuracy: 0.0079 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 3s 336us/step - loss: 0.0092 - accuracy: 0.0077 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 3s 342us/step - loss: 0.0092 - accuracy: 0.0075 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 3s 345us/step - loss: 0.0092 - accuracy: 0.0077 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 3s 370us/step - loss: 0.0092 - accuracy: 0.0071 - val_loss: 0.0092 - val_accuracy: 0.0084\n",
      "Test loss: 0.00915612373650074\n",
      "Test accuracy: 0.00839999970048666\n"
     ]
    }
   ],
   "source": [
    "initial_mlnn_loss = []\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(784, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(784, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, x_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, x_test))\n",
    "\n",
    "score = model.evaluate(x_test, x_test, verbose=0)\n",
    "initial_mlnn_loss.append(model.evaluate(x_test, x_test, verbose=0))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. apply noise to *_only_* the input of the autoencoder (not the output). demonstrate that your autoencoder can strip out noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather data and split into training and testing vars.\n",
    "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "\n",
    "xtrain = xtrain.astype('float32') / 255.\n",
    "\n",
    "xtest = xtest.astype('float32') / 255.\n",
    "xtrain = xtrain.reshape((len(xtrain), np.prod(xtrain.shape[1:])))\n",
    "xtest = xtest.reshape((len(xtest), np.prod(xtest.shape[1:])))\n",
    "xtrain.shape, xtest.shape\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.4503 - val_loss: 0.2654\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.2611 - val_loss: 0.2576\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2553 - val_loss: 0.2536\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2524 - val_loss: 0.2518\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2511 - val_loss: 0.2511\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2501 - val_loss: 0.2509\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2490 - val_loss: 0.2496\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2476 - val_loss: 0.2472\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2460 - val_loss: 0.2451\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2447 - val_loss: 0.2448\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2439 - val_loss: 0.2435\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2431 - val_loss: 0.2427\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2425 - val_loss: 0.2418\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2419 - val_loss: 0.2422\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2415 - val_loss: 0.2416\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2410 - val_loss: 0.2410\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2406 - val_loss: 0.2412\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2403 - val_loss: 0.2401\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2401 - val_loss: 0.2399\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2398 - val_loss: 0.2399\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2395 - val_loss: 0.2393\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2393 - val_loss: 0.2387\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2390 - val_loss: 0.2387\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2388 - val_loss: 0.2385\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2385 - val_loss: 0.2381\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2383 - val_loss: 0.2375\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2380 - val_loss: 0.2374\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2378 - val_loss: 0.2376\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2376 - val_loss: 0.2370\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2373 - val_loss: 0.2368\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2371 - val_loss: 0.2366\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2369 - val_loss: 0.2363\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2368 - val_loss: 0.2361\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2366 - val_loss: 0.2364\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2364 - val_loss: 0.2364\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2363 - val_loss: 0.2358\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2361 - val_loss: 0.2356\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2360 - val_loss: 0.2351\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2359 - val_loss: 0.2353\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2357 - val_loss: 0.2351\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2356 - val_loss: 0.2349\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2355 - val_loss: 0.2351\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2353 - val_loss: 0.2346\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2352 - val_loss: 0.2347\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2350 - val_loss: 0.2343\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2349 - val_loss: 0.2340\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2347 - val_loss: 0.2340\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2346 - val_loss: 0.2337\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2344 - val_loss: 0.2335\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2342 - val_loss: 0.2335\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2340 - val_loss: 0.2332\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2338 - val_loss: 0.2330\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2336 - val_loss: 0.2329\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2333 - val_loss: 0.2327\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2331 - val_loss: 0.2323\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2328 - val_loss: 0.2322\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2325 - val_loss: 0.2318\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2322 - val_loss: 0.2316\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2319 - val_loss: 0.2309\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2316 - val_loss: 0.2308\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2312 - val_loss: 0.2308\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2308 - val_loss: 0.2302\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2300 - val_loss: 0.2280\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2258 - val_loss: 0.2230\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2224 - val_loss: 0.2211\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2206 - val_loss: 0.2194\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2193 - val_loss: 0.2179\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2180 - val_loss: 0.2166\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2167 - val_loss: 0.2155\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2155 - val_loss: 0.2143\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2142 - val_loss: 0.2132\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2129 - val_loss: 0.2117\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2115 - val_loss: 0.2114\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2103 - val_loss: 0.2096\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2093 - val_loss: 0.2100\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2085 - val_loss: 0.2084\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2077 - val_loss: 0.2078\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2070 - val_loss: 0.2069\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2064 - val_loss: 0.2069\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2059 - val_loss: 0.2058\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2053 - val_loss: 0.2055\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2048 - val_loss: 0.2052\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2044 - val_loss: 0.2045\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2039 - val_loss: 0.2039\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2035 - val_loss: 0.2044\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2032 - val_loss: 0.2045\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2028 - val_loss: 0.2035\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2023 - val_loss: 0.2029\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2020 - val_loss: 0.2025\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2017 - val_loss: 0.2028\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2013 - val_loss: 0.2019\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2009 - val_loss: 0.2023\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2005 - val_loss: 0.2020\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2002 - val_loss: 0.2011\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1998 - val_loss: 0.2009\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1996 - val_loss: 0.2011\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1992 - val_loss: 0.2002\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1988 - val_loss: 0.1992\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1985 - val_loss: 0.1996\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1982 - val_loss: 0.1994\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.3697 - val_loss: 0.2643\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2603 - val_loss: 0.2573\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2530 - val_loss: 0.2477\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2415 - val_loss: 0.2337\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.2286 - val_loss: 0.2234\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2228 - val_loss: 0.2198\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2176 - val_loss: 0.2138\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2095 - val_loss: 0.2059\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2036 - val_loss: 0.2024\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1996 - val_loss: 0.1968\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1962 - val_loss: 0.1935\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1933 - val_loss: 0.1918\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1908 - val_loss: 0.1891\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1885 - val_loss: 0.1869\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1865 - val_loss: 0.1872\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1846 - val_loss: 0.1843\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1831 - val_loss: 0.1820\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1817 - val_loss: 0.1818\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1804 - val_loss: 0.1793\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1792 - val_loss: 0.1791\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1782 - val_loss: 0.1774\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1769 - val_loss: 0.1767\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1761 - val_loss: 0.1754\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1752 - val_loss: 0.1744\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1744 - val_loss: 0.1748\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1737 - val_loss: 0.1734\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1728 - val_loss: 0.1729\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1722 - val_loss: 0.1734\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1715 - val_loss: 0.1710\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1707 - val_loss: 0.1703\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1703 - val_loss: 0.1696\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1694 - val_loss: 0.1697\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1691 - val_loss: 0.1682\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1684 - val_loss: 0.1688\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1679 - val_loss: 0.1680\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1674 - val_loss: 0.1679\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1670 - val_loss: 0.1676\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1665 - val_loss: 0.1663\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1660 - val_loss: 0.1656\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1655 - val_loss: 0.1666\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1653 - val_loss: 0.1642\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1648 - val_loss: 0.1650\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1644 - val_loss: 0.1645\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1640 - val_loss: 0.1641\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1638 - val_loss: 0.1652\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1634 - val_loss: 0.1646\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1630 - val_loss: 0.1635\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1628 - val_loss: 0.1627\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1623 - val_loss: 0.1621\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1621 - val_loss: 0.1626\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1618 - val_loss: 0.1617\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1614 - val_loss: 0.1614\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1612 - val_loss: 0.1612\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1610 - val_loss: 0.1608\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1607 - val_loss: 0.1609\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1605 - val_loss: 0.1611\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1602 - val_loss: 0.1610\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1600 - val_loss: 0.1604\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1599 - val_loss: 0.1604\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1593 - val_loss: 0.1596\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1593 - val_loss: 0.1598\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1590 - val_loss: 0.1599\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1588 - val_loss: 0.1590\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1585 - val_loss: 0.1588\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1584 - val_loss: 0.1595\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1581 - val_loss: 0.1604\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1581 - val_loss: 0.1586\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1578 - val_loss: 0.1579\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1576 - val_loss: 0.1585\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1574 - val_loss: 0.1577\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1573 - val_loss: 0.1581\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1571 - val_loss: 0.1573\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1569 - val_loss: 0.1588\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1567 - val_loss: 0.1576\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1565 - val_loss: 0.1566\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1564 - val_loss: 0.1567\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1563 - val_loss: 0.1564\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1560 - val_loss: 0.1568\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1558 - val_loss: 0.1566\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1557 - val_loss: 0.1566\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1556 - val_loss: 0.1565\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1555 - val_loss: 0.1564\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1553 - val_loss: 0.1564\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1552 - val_loss: 0.1565\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1550 - val_loss: 0.1557\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1550 - val_loss: 0.1562\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1547 - val_loss: 0.1552\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1545 - val_loss: 0.1551\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1545 - val_loss: 0.1570\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1544 - val_loss: 0.1561\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1542 - val_loss: 0.1549\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1541 - val_loss: 0.1564\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1541 - val_loss: 0.1545\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1537 - val_loss: 0.1546\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1537 - val_loss: 0.1551\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1537 - val_loss: 0.1549\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1535 - val_loss: 0.1544\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1533 - val_loss: 0.1541\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1532 - val_loss: 0.1549\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1532 - val_loss: 0.1545\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.3263 - val_loss: 0.2651\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2576 - val_loss: 0.2510\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2437 - val_loss: 0.2396\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2374 - val_loss: 0.2344\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2289 - val_loss: 0.2217\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2160 - val_loss: 0.2105\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2085 - val_loss: 0.2063\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2040 - val_loss: 0.2008\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1994 - val_loss: 0.1967\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1933 - val_loss: 0.1888\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1881 - val_loss: 0.1842\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1840 - val_loss: 0.1818\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1810 - val_loss: 0.1794\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1786 - val_loss: 0.1777\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1766 - val_loss: 0.1752\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1748 - val_loss: 0.1729\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1731 - val_loss: 0.1711\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1716 - val_loss: 0.1705\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1704 - val_loss: 0.1696\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1689 - val_loss: 0.1683\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1676 - val_loss: 0.1663\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1662 - val_loss: 0.1641\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1645 - val_loss: 0.1637\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1630 - val_loss: 0.1630\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1614 - val_loss: 0.1582\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1596 - val_loss: 0.1572\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1585 - val_loss: 0.1566\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1572 - val_loss: 0.1546\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1559 - val_loss: 0.1576\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1548 - val_loss: 0.1535\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1539 - val_loss: 0.1521\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1531 - val_loss: 0.1525\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1524 - val_loss: 0.1523\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1517 - val_loss: 0.1510\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1511 - val_loss: 0.1499\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1505 - val_loss: 0.1494\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1500 - val_loss: 0.1493\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1493 - val_loss: 0.1485\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1489 - val_loss: 0.1490\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1485 - val_loss: 0.1474\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1482 - val_loss: 0.1486\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1475 - val_loss: 0.1470\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1472 - val_loss: 0.1481\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1468 - val_loss: 0.1467\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1465 - val_loss: 0.1459\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1462 - val_loss: 0.1453\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1457 - val_loss: 0.1448\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1453 - val_loss: 0.1451\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1451 - val_loss: 0.1445\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1447 - val_loss: 0.1448\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1445 - val_loss: 0.1444\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1441 - val_loss: 0.1434\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1439 - val_loss: 0.1433\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1436 - val_loss: 0.1452\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1433 - val_loss: 0.1435\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1430 - val_loss: 0.1426\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1428 - val_loss: 0.1439\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1426 - val_loss: 0.1424\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1422 - val_loss: 0.1411\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1422 - val_loss: 0.1414\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1418 - val_loss: 0.1418\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1417 - val_loss: 0.1411\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1414 - val_loss: 0.1421\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1412 - val_loss: 0.1411\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1411 - val_loss: 0.1408\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1408 - val_loss: 0.1409\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1406 - val_loss: 0.1397\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1404 - val_loss: 0.1401\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1402 - val_loss: 0.1398\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1401 - val_loss: 0.1402\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1398 - val_loss: 0.1397\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1397 - val_loss: 0.1421\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1397 - val_loss: 0.1400\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1393 - val_loss: 0.1398\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1391 - val_loss: 0.1408\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1391 - val_loss: 0.1385\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1389 - val_loss: 0.1390\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1387 - val_loss: 0.1383\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1385 - val_loss: 0.1382\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1384 - val_loss: 0.1393\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1382 - val_loss: 0.1385\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1381 - val_loss: 0.1378\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1379 - val_loss: 0.1390\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1378 - val_loss: 0.1383\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1376 - val_loss: 0.1384\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1375 - val_loss: 0.1376\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1374 - val_loss: 0.1370\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1371 - val_loss: 0.1368\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1372 - val_loss: 0.1367\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1369 - val_loss: 0.1374\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1369 - val_loss: 0.1374\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1366 - val_loss: 0.1367\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1365 - val_loss: 0.1372\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1364 - val_loss: 0.1362\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1364 - val_loss: 0.1356\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1362 - val_loss: 0.1367\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1360 - val_loss: 0.1365\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1359 - val_loss: 0.1372\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1359 - val_loss: 0.1360\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1359 - val_loss: 0.1359\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.3605 - val_loss: 0.2644\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2593 - val_loss: 0.2538\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2460 - val_loss: 0.2398\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2362 - val_loss: 0.2306\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2268 - val_loss: 0.2239\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2169 - val_loss: 0.2096\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2035 - val_loss: 0.1963\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1919 - val_loss: 0.1857\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1851 - val_loss: 0.1826\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1806 - val_loss: 0.1777\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1770 - val_loss: 0.1740\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1736 - val_loss: 0.1709\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1706 - val_loss: 0.1686\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1682 - val_loss: 0.1682\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1658 - val_loss: 0.1635\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1634 - val_loss: 0.1617\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1608 - val_loss: 0.1590\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1585 - val_loss: 0.1590\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1564 - val_loss: 0.1536\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1548 - val_loss: 0.1529\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1534 - val_loss: 0.1525\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1519 - val_loss: 0.1512\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1508 - val_loss: 0.1502\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1499 - val_loss: 0.1484\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1489 - val_loss: 0.1487\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1481 - val_loss: 0.1478\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1472 - val_loss: 0.1458\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1466 - val_loss: 0.1453\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1458 - val_loss: 0.1445\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1452 - val_loss: 0.1444\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1446 - val_loss: 0.1429\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1441 - val_loss: 0.1434\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1434 - val_loss: 0.1427\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1429 - val_loss: 0.1420\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1425 - val_loss: 0.1422\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1419 - val_loss: 0.1409\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1414 - val_loss: 0.1409\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1410 - val_loss: 0.1402\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1407 - val_loss: 0.1401\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1403 - val_loss: 0.1406\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1398 - val_loss: 0.1402\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1395 - val_loss: 0.1392\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1391 - val_loss: 0.1387\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1388 - val_loss: 0.1383\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1385 - val_loss: 0.1382\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1381 - val_loss: 0.1371\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1378 - val_loss: 0.1367\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1375 - val_loss: 0.1402\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1373 - val_loss: 0.1392\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1370 - val_loss: 0.1362\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1367 - val_loss: 0.1359\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1363 - val_loss: 0.1359\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1362 - val_loss: 0.1370\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1359 - val_loss: 0.1345\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1358 - val_loss: 0.1360\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1355 - val_loss: 0.1350\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1352 - val_loss: 0.1353\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1350 - val_loss: 0.1341\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1348 - val_loss: 0.1355\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1346 - val_loss: 0.1345\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1345 - val_loss: 0.1340\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1342 - val_loss: 0.1360\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1340 - val_loss: 0.1336\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1339 - val_loss: 0.1342\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1336 - val_loss: 0.1329\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1333 - val_loss: 0.1332\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1334 - val_loss: 0.1334\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1331 - val_loss: 0.1320\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1328 - val_loss: 0.1331\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1328 - val_loss: 0.1328\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1326 - val_loss: 0.1318\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1324 - val_loss: 0.1325\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1324 - val_loss: 0.1312\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1321 - val_loss: 0.1314\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1319 - val_loss: 0.1320\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1318 - val_loss: 0.1320\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1316 - val_loss: 0.1318\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1316 - val_loss: 0.1327\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1313 - val_loss: 0.1309\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1313 - val_loss: 0.1324\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1311 - val_loss: 0.1317\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1310 - val_loss: 0.1306\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1308 - val_loss: 0.1317\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1307 - val_loss: 0.1303\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1306 - val_loss: 0.1311\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1305 - val_loss: 0.1305\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1303 - val_loss: 0.1295\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1302 - val_loss: 0.1296\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1300 - val_loss: 0.1303\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1299 - val_loss: 0.1299\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1299 - val_loss: 0.1308\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1298 - val_loss: 0.1299\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1296 - val_loss: 0.1297\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1295 - val_loss: 0.1297\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1293 - val_loss: 0.1304\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1292 - val_loss: 0.1297\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1292 - val_loss: 0.1299\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1290 - val_loss: 0.1303\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1290 - val_loss: 0.1295\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1289 - val_loss: 0.1287\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.3491 - val_loss: 0.2628\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2587 - val_loss: 0.2546\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2477 - val_loss: 0.2413\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2352 - val_loss: 0.2279\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2199 - val_loss: 0.2124\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2076 - val_loss: 0.2032\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1990 - val_loss: 0.1954\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1937 - val_loss: 0.1918\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1891 - val_loss: 0.1865\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1848 - val_loss: 0.1818\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1804 - val_loss: 0.1786\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1759 - val_loss: 0.1714\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1720 - val_loss: 0.1686\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1693 - val_loss: 0.1674\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1670 - val_loss: 0.1648\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1652 - val_loss: 0.1633\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1635 - val_loss: 0.1624\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1619 - val_loss: 0.1602\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1606 - val_loss: 0.1594\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1592 - val_loss: 0.1572\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1580 - val_loss: 0.1564\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1555 - val_loss: 0.1547\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1541 - val_loss: 0.1530\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1527 - val_loss: 0.1510\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1515 - val_loss: 0.1511\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1502 - val_loss: 0.1500\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1492 - val_loss: 0.1501\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1480 - val_loss: 0.1467\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1471 - val_loss: 0.1465\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1462 - val_loss: 0.1467\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1453 - val_loss: 0.1440\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1443 - val_loss: 0.1442\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1433 - val_loss: 0.1408\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1421 - val_loss: 0.1416\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1412 - val_loss: 0.1403\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1402 - val_loss: 0.1394\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1394 - val_loss: 0.1377\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1387 - val_loss: 0.1386\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1381 - val_loss: 0.1373\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1375 - val_loss: 0.1372\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1370 - val_loss: 0.1350\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1364 - val_loss: 0.1354\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1359 - val_loss: 0.1350\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1354 - val_loss: 0.1353\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1350 - val_loss: 0.1352\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1345 - val_loss: 0.1339\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1342 - val_loss: 0.1330\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1338 - val_loss: 0.1329\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1334 - val_loss: 0.1324\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1330 - val_loss: 0.1331\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1327 - val_loss: 0.1312\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1323 - val_loss: 0.1320\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1319 - val_loss: 0.1324\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1315 - val_loss: 0.1296\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1312 - val_loss: 0.1300\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1309 - val_loss: 0.1308\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1304 - val_loss: 0.1308\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1300 - val_loss: 0.1292\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1295 - val_loss: 0.1292\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1291 - val_loss: 0.1279\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1287 - val_loss: 0.1273\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1282 - val_loss: 0.1274\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1279 - val_loss: 0.1269\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1274 - val_loss: 0.1265\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1271 - val_loss: 0.1274\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1268 - val_loss: 0.1263\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1265 - val_loss: 0.1253\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1261 - val_loss: 0.1261\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1258 - val_loss: 0.1246\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1256 - val_loss: 0.1257\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1254 - val_loss: 0.1244\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1250 - val_loss: 0.1247\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1249 - val_loss: 0.1245\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1245 - val_loss: 0.1249\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1243 - val_loss: 0.1242\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1241 - val_loss: 0.1247\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1238 - val_loss: 0.1242\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1237 - val_loss: 0.1234\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1235 - val_loss: 0.1225\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1233 - val_loss: 0.1244\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1232 - val_loss: 0.1226\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1229 - val_loss: 0.1233\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1228 - val_loss: 0.1224\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1226 - val_loss: 0.1236\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1224 - val_loss: 0.1223\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1222 - val_loss: 0.1224\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1219 - val_loss: 0.1220\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1218 - val_loss: 0.1228\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1217 - val_loss: 0.1213\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1215 - val_loss: 0.1217\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1214 - val_loss: 0.1209\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1211 - val_loss: 0.1217\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1210 - val_loss: 0.1210\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1209 - val_loss: 0.1216\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1208 - val_loss: 0.1214\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1206 - val_loss: 0.1209\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1204 - val_loss: 0.1206\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1203 - val_loss: 0.1199\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1201 - val_loss: 0.1207\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.3360 - val_loss: 0.2628\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2568 - val_loss: 0.2497\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2434 - val_loss: 0.2371\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2286 - val_loss: 0.2191\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2098 - val_loss: 0.2033\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1977 - val_loss: 0.1907\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1870 - val_loss: 0.1839\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1800 - val_loss: 0.1756\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1749 - val_loss: 0.1706\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1706 - val_loss: 0.1677\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1664 - val_loss: 0.1625\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1623 - val_loss: 0.1583\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1592 - val_loss: 0.1565\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1564 - val_loss: 0.1545\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1537 - val_loss: 0.1516\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1511 - val_loss: 0.1478\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1482 - val_loss: 0.1451\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1456 - val_loss: 0.1439\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1435 - val_loss: 0.1420\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1415 - val_loss: 0.1392\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1398 - val_loss: 0.1380\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1384 - val_loss: 0.1360\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1372 - val_loss: 0.1364\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1361 - val_loss: 0.1338\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1349 - val_loss: 0.1334\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1341 - val_loss: 0.1324\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1332 - val_loss: 0.1324\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1323 - val_loss: 0.1299\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1316 - val_loss: 0.1319\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1308 - val_loss: 0.1289\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1301 - val_loss: 0.1291\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1295 - val_loss: 0.1278\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1288 - val_loss: 0.1284\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1282 - val_loss: 0.1278\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1277 - val_loss: 0.1263\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1271 - val_loss: 0.1255\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1265 - val_loss: 0.1258\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1261 - val_loss: 0.1253\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1255 - val_loss: 0.1254\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1251 - val_loss: 0.1240\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1247 - val_loss: 0.1235\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1243 - val_loss: 0.1241\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1239 - val_loss: 0.1233\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1235 - val_loss: 0.1224\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1232 - val_loss: 0.1228\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1227 - val_loss: 0.1221\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1223 - val_loss: 0.1217\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1220 - val_loss: 0.1216\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1217 - val_loss: 0.1210\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1213 - val_loss: 0.1195\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1208 - val_loss: 0.1199\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1205 - val_loss: 0.1201\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1202 - val_loss: 0.1186\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1198 - val_loss: 0.1192\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1194 - val_loss: 0.1187\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1191 - val_loss: 0.1180\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1186 - val_loss: 0.1175\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1182 - val_loss: 0.1176\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1179 - val_loss: 0.1179\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1176 - val_loss: 0.1161\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1172 - val_loss: 0.1159\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1170 - val_loss: 0.1168\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1166 - val_loss: 0.1163\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1164 - val_loss: 0.1150\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1160 - val_loss: 0.1171\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1160 - val_loss: 0.1156\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1156 - val_loss: 0.1148\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1154 - val_loss: 0.1140\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1151 - val_loss: 0.1142\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1151 - val_loss: 0.1138\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1147 - val_loss: 0.1142\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1146 - val_loss: 0.1136\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1144 - val_loss: 0.1150\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1140 - val_loss: 0.1140\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1139 - val_loss: 0.1132\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1137 - val_loss: 0.1130\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1135 - val_loss: 0.1134\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1133 - val_loss: 0.1143\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1131 - val_loss: 0.1121\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1129 - val_loss: 0.1130\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1127 - val_loss: 0.1127\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1125 - val_loss: 0.1127\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1125 - val_loss: 0.1125\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1123 - val_loss: 0.1112\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1122 - val_loss: 0.1111\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1120 - val_loss: 0.1113\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1117 - val_loss: 0.1107\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1116 - val_loss: 0.1112\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1115 - val_loss: 0.1112\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1113 - val_loss: 0.1107\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1112 - val_loss: 0.1103\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1109 - val_loss: 0.1108\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1110 - val_loss: 0.1105\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1107 - val_loss: 0.1115\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1106 - val_loss: 0.1106\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1104 - val_loss: 0.1101\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1103 - val_loss: 0.1092\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1103 - val_loss: 0.1102\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1100 - val_loss: 0.1095\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1100 - val_loss: 0.1100\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3292 - val_loss: 0.2648\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2584 - val_loss: 0.2535\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2452 - val_loss: 0.2385\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2324 - val_loss: 0.2256\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2186 - val_loss: 0.2114\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2038 - val_loss: 0.1987\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1937 - val_loss: 0.1917\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1870 - val_loss: 0.1837\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1812 - val_loss: 0.1790\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1755 - val_loss: 0.1734\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1704 - val_loss: 0.1679\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1657 - val_loss: 0.1608\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1617 - val_loss: 0.1593\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1584 - val_loss: 0.1549\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1556 - val_loss: 0.1533\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1530 - val_loss: 0.1513\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1506 - val_loss: 0.1472\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1486 - val_loss: 0.1473\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1466 - val_loss: 0.1454\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1450 - val_loss: 0.1432\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1434 - val_loss: 0.1421\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1420 - val_loss: 0.1397\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1406 - val_loss: 0.1395\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1395 - val_loss: 0.1392\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1384 - val_loss: 0.1372\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1374 - val_loss: 0.1354\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1364 - val_loss: 0.1357\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1355 - val_loss: 0.1349\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1346 - val_loss: 0.1333\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1340 - val_loss: 0.1329\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1332 - val_loss: 0.1331\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1325 - val_loss: 0.1318\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1317 - val_loss: 0.1312\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1311 - val_loss: 0.1293\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1305 - val_loss: 0.1309\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1299 - val_loss: 0.1294\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1293 - val_loss: 0.1284\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1289 - val_loss: 0.1307\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1282 - val_loss: 0.1281\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1279 - val_loss: 0.1264\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1274 - val_loss: 0.1265\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1269 - val_loss: 0.1252\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1265 - val_loss: 0.1246\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1260 - val_loss: 0.1248\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1257 - val_loss: 0.1249\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1252 - val_loss: 0.1245\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1249 - val_loss: 0.1245\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1245 - val_loss: 0.1233\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1242 - val_loss: 0.1238\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1239 - val_loss: 0.1229\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1235 - val_loss: 0.1219\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1232 - val_loss: 0.1234\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1229 - val_loss: 0.1224\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1226 - val_loss: 0.1212\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1223 - val_loss: 0.1223\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1220 - val_loss: 0.1221\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1218 - val_loss: 0.1209\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1214 - val_loss: 0.1214\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1212 - val_loss: 0.1215\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1210 - val_loss: 0.1212\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1206 - val_loss: 0.1204\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1205 - val_loss: 0.1200\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1203 - val_loss: 0.1203\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1201 - val_loss: 0.1192\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1198 - val_loss: 0.1192\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1195 - val_loss: 0.1196\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1194 - val_loss: 0.1203\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1192 - val_loss: 0.1185\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1189 - val_loss: 0.1190\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1186 - val_loss: 0.1185\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1184 - val_loss: 0.1194\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1184 - val_loss: 0.1190\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1182 - val_loss: 0.1173\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1180 - val_loss: 0.1173\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1178 - val_loss: 0.1199\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1176 - val_loss: 0.1170\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1174 - val_loss: 0.1168\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1173 - val_loss: 0.1170\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1170 - val_loss: 0.1159\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1169 - val_loss: 0.1186\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1168 - val_loss: 0.1161\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1166 - val_loss: 0.1165\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1165 - val_loss: 0.1169\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1163 - val_loss: 0.1160\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1159 - val_loss: 0.1167\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1161 - val_loss: 0.1157\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1158 - val_loss: 0.1158\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1157 - val_loss: 0.1154\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1155 - val_loss: 0.1149\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1154 - val_loss: 0.1152\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1152 - val_loss: 0.1144\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1152 - val_loss: 0.1159\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1150 - val_loss: 0.1146\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1148 - val_loss: 0.1154\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1149 - val_loss: 0.1142\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1147 - val_loss: 0.1148\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1145 - val_loss: 0.1144\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1144 - val_loss: 0.1152\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1142 - val_loss: 0.1141\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1141 - val_loss: 0.1145\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.3218 - val_loss: 0.2632\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2577 - val_loss: 0.2535\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2420 - val_loss: 0.2303\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2217 - val_loss: 0.2120\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2050 - val_loss: 0.1965\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1935 - val_loss: 0.1874\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1845 - val_loss: 0.1801\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1763 - val_loss: 0.1716\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1697 - val_loss: 0.1655\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1643 - val_loss: 0.1622\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1594 - val_loss: 0.1553\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1553 - val_loss: 0.1518\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1517 - val_loss: 0.1482\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1491 - val_loss: 0.1470\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1466 - val_loss: 0.1426\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1444 - val_loss: 0.1432\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1420 - val_loss: 0.1400\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1399 - val_loss: 0.1380\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1377 - val_loss: 0.1369\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1362 - val_loss: 0.1353\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1348 - val_loss: 0.1330\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1334 - val_loss: 0.1319\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1322 - val_loss: 0.1302\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1311 - val_loss: 0.1292\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1300 - val_loss: 0.1285\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1290 - val_loss: 0.1273\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1281 - val_loss: 0.1261\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1272 - val_loss: 0.1253\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1262 - val_loss: 0.1253\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1253 - val_loss: 0.1249\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1244 - val_loss: 0.1226\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1235 - val_loss: 0.1224\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1227 - val_loss: 0.1202\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1220 - val_loss: 0.1196\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1212 - val_loss: 0.1193\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1206 - val_loss: 0.1180\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1199 - val_loss: 0.1189\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1193 - val_loss: 0.1183\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1186 - val_loss: 0.1177\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1181 - val_loss: 0.1173\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1175 - val_loss: 0.1160\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1172 - val_loss: 0.1151\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1165 - val_loss: 0.1156\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1161 - val_loss: 0.1144\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1157 - val_loss: 0.1158\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1152 - val_loss: 0.1136\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1148 - val_loss: 0.1151\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1144 - val_loss: 0.1138\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1139 - val_loss: 0.1132\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1136 - val_loss: 0.1121\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1132 - val_loss: 0.1123\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1128 - val_loss: 0.1118\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1123 - val_loss: 0.1105\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1120 - val_loss: 0.1108\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1117 - val_loss: 0.1113\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1113 - val_loss: 0.1102\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1110 - val_loss: 0.1106\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1107 - val_loss: 0.1102\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1104 - val_loss: 0.1095\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1100 - val_loss: 0.1081\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1098 - val_loss: 0.1107\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1095 - val_loss: 0.1084\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1092 - val_loss: 0.1077\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1089 - val_loss: 0.1078\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1087 - val_loss: 0.1089\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1085 - val_loss: 0.1104\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1081 - val_loss: 0.1079\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1079 - val_loss: 0.1068\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1077 - val_loss: 0.1067\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1075 - val_loss: 0.1069\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1073 - val_loss: 0.1070\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1071 - val_loss: 0.1058\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1069 - val_loss: 0.1061\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1067 - val_loss: 0.1064\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1065 - val_loss: 0.1064\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1063 - val_loss: 0.1056\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1061 - val_loss: 0.1060\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1060 - val_loss: 0.1052\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1058 - val_loss: 0.1061\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1056 - val_loss: 0.1047\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1054 - val_loss: 0.1045\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1053 - val_loss: 0.1047\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1050 - val_loss: 0.1045\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1049 - val_loss: 0.1051\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1048 - val_loss: 0.1045\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1046 - val_loss: 0.1048\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1044 - val_loss: 0.1040\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1042 - val_loss: 0.1036\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1041 - val_loss: 0.1041\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1041 - val_loss: 0.1041\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1038 - val_loss: 0.1039\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1038 - val_loss: 0.1036\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1036 - val_loss: 0.1023\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1034 - val_loss: 0.1035\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1034 - val_loss: 0.1023\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1031 - val_loss: 0.1026\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1031 - val_loss: 0.1023\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1029 - val_loss: 0.1032\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1029 - val_loss: 0.1019\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1027 - val_loss: 0.1030\n"
     ]
    }
   ],
   "source": [
    "loss_score_noise = {}\n",
    "for iter_dim in range(2,18,2):\n",
    "    # this is the size of our encoded representations\n",
    "    encoding_dim = iter_dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "    # this is our input placeholder\n",
    "    x = input_img = Input(shape=(784,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(x)\n",
    "\n",
    "\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    x = Dense(128, activation='relu')(encoded)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    decoded = Dense(784, activation='sigmoid')(x)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "\n",
    "    encoder = Model(input_img, encoded)\n",
    "\n",
    "    # create a placeholder for an encoded (32-dimensional) input\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "    # retrieve the last layer of the autoencoder model\n",
    "    dcd1 = autoencoder.layers[-1]\n",
    "    dcd2 = autoencoder.layers[-2]\n",
    "    dcd3 = autoencoder.layers[-3]\n",
    "\n",
    "    # create the decoder model\n",
    "    decoder = Model(encoded_input, dcd1(dcd2(dcd3(encoded_input))))\n",
    "\n",
    "    # compile autoencoder \n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    \n",
    "    autoencoder.fit(random_noise(xtrain), xtrain,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(random_noise(xtest), xtest))\n",
    "    \n",
    "    loss_score_noise[iter_dim] = autoencoder.evaluate(xtrain, xtrain, verbose = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({2: 0.19573124536673228,\n",
       "  4: 0.15351997696956,\n",
       "  6: 0.14371606947580973,\n",
       "  8: 0.12235987691084543,\n",
       "  10: 0.11384244225819906,\n",
       "  12: 0.10793483013709386,\n",
       "  14: 0.10745247059265772,\n",
       "  16: 0.1057592625617981},\n",
       " {2: 0.20028356336752573,\n",
       "  4: 0.15801826189359028,\n",
       "  6: 0.14310619707107544,\n",
       "  8: 0.13236936440467834,\n",
       "  10: 0.12814583059151968,\n",
       "  12: 0.11356325762669245,\n",
       "  14: 0.11811600044171015,\n",
       "  16: 0.10873440016508103})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_score,loss_score_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x288 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_imgs = encoder.predict(xtest)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 20  # how many digits we will display\n",
    "plt.figure(figsize=(40, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(xtest[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
